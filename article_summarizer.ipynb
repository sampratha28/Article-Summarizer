{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sampratha28/Article-Summarizer/blob/main/article_summarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wFsjm9qoRqt"
      },
      "outputs": [],
      "source": [
        "#problem statement - create a article summarizer to summarise long and complex text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#two types of summarisation - paragraph, bullet points\n",
        "#control length of summary generated"
      ],
      "metadata": {
        "id": "Dojc_rnrod2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Article Summarizer Streamlit UI"
      ],
      "metadata": {
        "id": "1D9DnFwiVxK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOCtuYt1qp-M",
        "outputId": "46f60634-558e-4ddf-ff50-3383dcd6e6a0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yY46OUwpq2Ke",
        "outputId": "429fef02-193b-4fb2-fd0d-b7a1e6e1be63"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.42.2-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.28.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.23.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.42.2-py2.py3-none-any.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.42.2 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "from transformers import AutoTokenizer, pipeline, GPTNeoForCausalLM\n",
        "import torch\n",
        "import os\n",
        "\n",
        "offload_dir = \"./offload_folder\"\n",
        "os.makedirs(offload_dir, exist_ok=True)\n",
        "\n",
        "#falcon = tiiuae/falcon-7b-instruct\n",
        "#distilgpt2\n",
        "class ArticleSummarizer:\n",
        "    def __init__(self, model_name=\"distilgpt2\"):\n",
        "        #Load the model and tokenizer\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.text_generator = pipeline(\n",
        "            \"text-generation\",\n",
        "            model=model_name,\n",
        "            tokenizer=self.tokenizer,\n",
        "            torch_dtype=torch.bfloat16,\n",
        "            trust_remote_code=True,\n",
        "            device_map=\"auto\",\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def generate_summary(self, input_text, summary_format, summary_length):\n",
        "        # Construct the prompt based on the selected summary length\n",
        "\n",
        "        if summary_format == 'Bullet Points':\n",
        "            prompt = f\"\"\"Summarize the following text in bullet points, highlighting the most important details and key information. Text:{input_text}\\n Summary:\n",
        "            Example text: In the ancient land of Eldoria, a realm forgotten by time, nestled between the towering peaks of the Seraph Mountains and the whispering depths of the Enchanted Forest, there existed a kingdom unlike any other. This was a land where magic flowed as freely as the rivers that carved their paths through the valleys, where mythical creatures roamed the skies and forests, and where the very earth hummed with an ancient power that echoed the songs of the stars.\n",
        "\n",
        "For centuries, the Kingdom of Eldoria thrived under the wise and benevolent rule of the Aetherian dynasty. The Aetherians were a noble lineage of rulers who possessed the ability to commune with the elements, drawing strength from the earth, the winds, the waters, and the flames. This connection to the elemental forces granted them wisdom beyond their years and power that was revered by their people. Under their rule, Eldoria became a beacon of peace, prosperity, and harmony, where all beings, whether human, elf, dwarf, or otherwise, lived in unity.\n",
        "\n",
        "But as with all things in the world, change was inevitable.\n",
        "            Example Summary: Location: Eldoria, an ancient and mystical land situated between the Seraph Mountains and the Enchanted Forest.\n",
        "Environment: The kingdom is characterized by abundant magic, mythical creatures, and a land imbued with ancient power.\n",
        "Ruling Dynasty: The Aetherian dynasty, known for their wisdom and ability to commune with elemental forces (earth, wind, water, fire).\n",
        "Governance: The Aetherians' rule brought peace, prosperity, and harmony to Eldoria, with unity among all beings (humans, elves, dwarves, etc.).\n",
        "Current Situation: The text hints at impending change in Eldoria.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "        else:\n",
        "          prompt = f\"Summarize the following text in a concise paragraph: {input_text}\\n Summary:\"\n",
        "\n",
        "        if summary_length=='Short':\n",
        "          # Generate the summary using the text generation model\n",
        "          sequences = self.text_generator(\n",
        "    prompt,\n",
        "    max_new_tokens=256,\n",
        "    do_sample=True,\n",
        "    top_k=10,  # Only sample from the top 10 tokens\n",
        "    top_p=0.9,  # Include tokens until 90% of probability mass is covered\n",
        "    temperature=1.0,  # Default temperature\n",
        "    num_return_sequences=1,\n",
        "    no_repeat_ngram_size=2,  # Prevent repetitive sequences\n",
        "    eos_token_id=self.tokenizer.eos_token_id,\n",
        ")\n",
        "        else:\n",
        "          sequences = self.text_generator(\n",
        "    prompt,\n",
        "    max_new_tokens=412,\n",
        "    do_sample=True,\n",
        "    top_k=10,  # Only sample from the top 10 tokens\n",
        "    top_p=0.9,  # Include tokens until 90% of probability mass is covered\n",
        "    temperature=1.0,  # Default temperature\n",
        "    num_return_sequences=1,\n",
        "    no_repeat_ngram_size=2,  # Prevent repetitive sequences\n",
        "    eos_token_id=self.tokenizer.eos_token_id,\n",
        ")\n",
        "\n",
        "        summary = sequences[0]['generated_text'].replace(prompt, \"\").strip()\n",
        "        print(summary)\n",
        "\n",
        "        return summary\n",
        "\n",
        "# Streamlit app layout\n",
        "class SummarizerApp:\n",
        "    def __init__(self):\n",
        "        self.summarizer = ArticleSummarizer()\n",
        "\n",
        "    def run(self):\n",
        "        st.title(\"Article Summarizer\")\n",
        "\n",
        "        # Text input\n",
        "        user_input = st.text_area(\"Enter the text you want to summarize:\", height=200)\n",
        "\n",
        "        # Summary format selection\n",
        "        summary_format = st.radio(\n",
        "            \"Select the summary format:\",\n",
        "            ('Paragraph', 'Bullet Points')\n",
        "        )\n",
        "\n",
        "        # Summary length selection\n",
        "        summary_length = st.radio(\n",
        "            \"Select the summary length:\",\n",
        "            ('Short', 'Long')\n",
        "        )\n",
        "\n",
        "        # Generate and display the summary\n",
        "        if st.button(\"Generate Summary\"):\n",
        "            if user_input:\n",
        "                summary = self.summarizer.generate_summary(user_input, summary_format, summary_length)\n",
        "                st.subheader(\"Summary:\")\n",
        "                st.text(summary)\n",
        "            else:\n",
        "                st.warning(\"Please enter some text to summarize.\")\n",
        "\n",
        "# Run the app\n",
        "if __name__ == \"__main__\":\n",
        "    app = SummarizerApp()\n",
        "    app.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hELdUpkMXAoc",
        "outputId": "81913ccb-865b-4042-9fdb-3bb14785085c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgd4D3OOXFH7",
        "outputId": "9d357ac1-351d-41fb-fe14-f1f38269029c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K\n",
            "added 22 packages in 2s\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqgnPX7Ad9nh",
        "outputId": "1a67392e-7501-4fbb-b4d5-db91c39d93c6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Password/Enpoint IP for localtunnel is: 34.124.250.230\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWwWUxMSYpcR",
        "outputId": "c19f7930-1ee9-4775-da03-4fdb2031ecd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.124.250.230:8501\u001b[0m\n",
            "\u001b[0m\n",
            "your url is: https://gentle-trains-ask.loca.lt\n",
            "2025-03-03 16:13:49.704910: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741018429.729159    1108 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741018429.736850    1108 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-03 16:13:49.762030: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "tokenizer_config.json: 100% 26.0/26.0 [00:00<00:00, 144kB/s]\n",
            "config.json: 100% 762/762 [00:00<00:00, 4.69MB/s]\n",
            "vocab.json: 100% 1.04M/1.04M [00:00<00:00, 4.88MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 2.13MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 3.20MB/s]\n",
            "model.safetensors: 100% 353M/353M [00:01<00:00, 191MB/s]\n",
            "generation_config.json: 100% 124/124 [00:00<00:00, 1.01MB/s]\n",
            "Device set to use cuda:0\n",
            "2025-03-03 16:14:02.998 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 345, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "I think this is the best example of what the compiler should consider when evaluating the output of a given program. The result is that a program should always be evaluated in order to be able to perform the task of executing a particular program as efficiently as possible. This is not the only way to think about how a compiler might evaluate. I also like to see that the program can do more than just run a function, but it also allows a more efficient program to execute the same task as the previous. In addition, there are other techniques that could be used to evaluate the input output, for example the ability to write a simple script, and then use this method to read the outputs of various programs.\n",
            "The main goal of this approach is to use the language to produce a functional compiler that can run the code in parallel with a standard library. While the current version of the Haskell programming language is written in the old style, this means that most of our language's code is actually generated from the source code. It is also a good idea to develop a library that will run in both parallel and parallel, which can be a lot of different things. For example, I would like a language with two languages that allow us to run parallel programs without having to do the processing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gWNgmys_XD7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kBOvrIp1VwHi"
      }
    }
  ]
}